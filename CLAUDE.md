# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## プロジェクト概要

車輪付きロボットの2Dシミュレーター。差動駆動ロボットがフィールド内のターゲットを探索するシステム。

## ロボットシミュレーション構成
### フィールド仕様
- 80cm × 160cm、1cm解像度グリッド（有効エリア）
- 12個のターゲット（40cm間隔）
	- ターゲットの配置は、長辺に5個ずつ、短辺に3個ずつ、四隅に1個ずつ(重複あり):合計12個
	- ターゲット間隔は40cm
	- ターゲットの半径は3cm
	- **ターゲットの中心はフィールドの境界線上に配置**
    - ターゲットの周囲に黒い円(5cm幅)があり、フォトセンサで検出可能
- フィールドには壁がなく、フィールド外周には壁の代わりに黒いラインがあり、フォトセンサで検出可能、ライン幅は5cm
- **黒いラインはフィールドサイズ(80×160cm)に含まれず、外周に配置**
- **全体サイズ: 90cm × 170cm (黒ライン込み)**
- **座標系: 黒ライン50mm、フィールド有効エリア50mm～850mm(Y軸), 50mm～1650mm(X軸)**
- ブラウザベース2D描画（HTML5 Canvas/SVG）

### ロボット仕様
- 車体正面にサーボ付き距離センサー（-90°～90°回転、2cm-4m測定範囲、目標検出用途）
- ロボット中心から前方25cm（車体前端15cm+10cm）の位置に下向きに左右フォトセンサー（白黒検出）
- 最大速度: 20cm/s、最大回転速度: 90°/s
- 制御コンピュータはarduino
- サイズ：30cm × 30cm × 30cm
- 移動方式：左右独立2輪（差動駆動）
- 初期位置：フィールド中央・縦向き
- *距離センサとモータとサーボの誤差は定数にて変更可能*

### 制御システム
主要な組み込み制御関数:
- `setServo(angle)`-> (): 距離センサーサーボ制御
- `getDistance()` -> int: 距離センサー読み取り（スタブでは0を返す）
- `getR_Photo()` / `getL_Photo()` -> bool: フォトセンサー読み取り（スタブではfalseを返す）
- `setMotorSpeeds(leftSpeed, rightSpeed)`:差動駆動制御
- `delay(time_ms)`: 一時停止する時間 (unsigned long)。単位はミリ秒 
- `milis()`-> unsigned long int: 実行中のプログラムがスタートしてからの時間 (unsigned long) 
- `found()` -> bool: ターゲットを発見したかどうかを返す

### スコアリングシステム
- 未発見ターゲット到達で10点
- 発見済みターゲット再訪で2点
- 連続で同一のターゲットを訪問した場合の加算はない。
- ターゲット到達時にコンソール・GUIに表示
- ターゲット発見条件：フォトセンサのどちらか黒検知 AND 距離センサ ≤ 3cm（パラメータ調整済み）


## シミュレーション環境
- ブラウザ上でリアルタイム2D描画
- ロボット、ターゲット、黒ライン、移動履歴の可視化
- 物理演算は簡易（タイムステップ単位の移動・回転）
- 実行速度：リアルタイム/高速実行モード切替可能

### 安全システム
- **衝突判定**: ロボット本体（30×30cm）の4角がフィールド内の黒ラインエリアに侵入した場合
- **落下判定**: ロボット本体の4角がフィールド全体から外れた場合
- **ゲームオーバー**: 衝突または落下発生時にシミュレーション停止、リセットで再開可能
- **衝突回避**: 探索アルゴリズムにフォトセンサーと距離センサーを使った安全制御を組み込み



## ロボット制御
- 自律制御アルゴリズム（プログラムで指定・手動制御不可）
- デフォルト実装：壁沿い探索アルゴリズム
- 制御ロジック部分はプログラムとして差し替え可能に設計


## その他
- 構成：HTML/CSS/JavaScriptによる単一ページアプリ
- 設定やターゲット配置はコード修正で調整可能


## 開発ワークフロー
- テストの仕様書は、test.mdに追記していく。

1. センサ関数の実装
2. センサ関数のテスト(test.js)
   <!-- 1. センサのテストはdenoを使用 -->
3. フィールドを実装
4. フィールドのテスト(スコアリングシステムのテストも含む)
5. UIの作成
6. センサ、フィールド、UIの統合
状況に応じて以降は実装を行う。